{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Written by Andrew Hamilton, TLU Physics, Class of 2019\n",
    "#Part of a research project done in collaboration with Dr. Josh Fuchs during the Summer of 2018 through the Fall of 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from astropy.table import Table\n",
    "from astropy.io import ascii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## •Organizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def super_tableizer(data):\n",
    "    \"\"\"Super Tableizer\n",
    "    \n",
    "    Will combine given tables of astro data (as long as the first 2 columns are ra and dec), into one large table\n",
    "    \n",
    "    Args:\n",
    "        Data (list): List containing data tables that you want to combine together\n",
    "        \n",
    "    Return:\n",
    "        (Astropy.Table): Combined Table\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    datatable = Table()\n",
    "    for dataset in data:\n",
    "        if count == 0:\n",
    "            for name in dataset.colnames:\n",
    "                datatable[name] = dataset[name]\n",
    "        else:\n",
    "            for name in dataset.colnames[2:]:\n",
    "                datatable[name] = dataset[name]\n",
    "        count += 1\n",
    "                \n",
    "    return datatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def min_to_deg(value):\n",
    "    \"\"\"Min-to-Deg\n",
    "    Converts RA/Dec values from deg-min-sec format to decimal degrees, to interface with other data formats\n",
    "    This function should be valid for any dataset using this format, so here's hoping!\n",
    "    \n",
    "    Args:\n",
    "        value (str): dg-mn-se.conds format coordinates\n",
    "        \n",
    "    Returns:\n",
    "        (float): decimal degree coordinates    \n",
    "    \"\"\"\n",
    "    \n",
    "    degrees = []\n",
    "    minutes = []\n",
    "    seconds = []\n",
    "    \n",
    "    coord = [degrees, minutes, seconds]\n",
    "    index_num = 0\n",
    "    \n",
    "    for char in value:\n",
    "        if char == ' ':\n",
    "            index_num += 1\n",
    "        else:\n",
    "            coord[index_num].append(char)\n",
    "    \n",
    "    #I didn't know how to turn this set of lists and ints and such to values\n",
    "    #until I found this solution on ~the Internet~\n",
    "    #https://stackoverflow.com/a/490020        \n",
    "    deg_val = int(''.join(map(str,degrees)))\n",
    "    min_val = int(''.join(map(str,minutes)))\n",
    "    sec_val = float(''.join(map(str,seconds)))\n",
    "    \n",
    "    decimal_coord = deg_val + min_val/60 + sec_val/60**2\n",
    "            \n",
    "    return decimal_coord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## •Analyzing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def index_range_finder(color_index, deviations):\n",
    "    \"\"\"Color Index Range Finder\n",
    "    \n",
    "    Determines the approximate range of a cluster of Color Indices for a LARP\n",
    "    \n",
    "    Modelled from a cluster found in the I-Z indices of 8 of the 9 known LARPs\n",
    "    \n",
    "    Args:\n",
    "        color_index (list): contains indices of the known LARPs\n",
    "        deviations (float?): number of standard deviations from mean to calc range (int or float preferred?)\n",
    "        \n",
    "    Returns:\n",
    "        (float): lower bound of the cluster range\n",
    "        (float): upper bound of the cluster range\n",
    "    \n",
    "    \"\"\"\n",
    "    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    #if you want modular stdevs, here's the place to do so\n",
    "    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    stdev = np.std(color_index)\n",
    "    low_bound = np.mean(color_index)-stdev*deviations\n",
    "    up_bound = np.mean(color_index)+stdev*deviations\n",
    "    \n",
    "    return low_bound, up_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auto_cluster_finder(data, a, b, deviations, threshold):\n",
    "    \"\"\"Auto Cluster Finder\n",
    "    \n",
    "    Automatically finds potential clusters\n",
    "    \n",
    "    Args:\n",
    "        data (astropy.Table): Astropy data containing however many magnitudes\n",
    "        a (str): First magnitude, will be subtracted from to get index\n",
    "        b (str): Second magnitude, will be subtracted from a to get index\n",
    "        deviations (float?): number of standard deviations from mean to calc range (int or float preferred?)\n",
    "        threshold (float): fraction of stars contained within cluster region for cluster to be considered valid\n",
    "        \n",
    "    Returns:\n",
    "        (list): List containing lbound, ubound, mag_a, mag_b, and if the filter is valid\n",
    "    \"\"\"\n",
    "    \n",
    "    x = data[a] - data[b]\n",
    "    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    #if you want modular stdevs, here's the place to do so\n",
    "    #go thru the following function to find it!!!!!!!!!!!!\n",
    "    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    c, d = index_range_finder(x, deviations)\n",
    "    count = 0\n",
    "    for item in x:\n",
    "        if c <= item and item <= d:\n",
    "            count += 1 \n",
    "            \n",
    "    percent = count/len(data['ra'])\n",
    "    \n",
    "    if percent > threshold:\n",
    "        print(a + '-' + b)\n",
    "        print('Suitable Filter found!',str(count),'stars in range.')\n",
    "        print('Lbound:',str(c),', Ubound:',str(d))\n",
    "        good_filter = True\n",
    "    else:\n",
    "        #uncomment the line below if you want it to print for ~every single possible filter~\n",
    "        #print('Filter unsuitable. Only',str(count),'stars in range.')\n",
    "        good_filter = False\n",
    "        \n",
    "    return [c, d, a, b, good_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_generator(data, deviations,threshold):\n",
    "    \"\"\"Filter Generator\n",
    "    \n",
    "    Generates possible filters for LARPs\n",
    "    \n",
    "    Args:\n",
    "        data (astropy.Table): Astropy data\n",
    "        deviations (float?): number of standard deviations from mean to calc range (int or float preferred?)\n",
    "        threshold (float): fraction of stars contained within cluster region for cluster to be considered valid\n",
    "        \n",
    "    Returns:\n",
    "        (list): list containing filters using my standard 1-D filter format, includes insufficient ones\n",
    "    \"\"\"\n",
    "    column_names = data.colnames\n",
    "    \n",
    "    x = len(column_names)\n",
    "    indices = []\n",
    "    for a in range(2,x):\n",
    "        for b in range(2,x):\n",
    "            if a < b:\n",
    "                #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "                #if you want modular stdevs, here's the place to do so\n",
    "                #go thru the following function to find it!!!!!!!!!!!!\n",
    "                #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "                filt = auto_cluster_finder(data, column_names[a], column_names[b], deviations,threshold)\n",
    "                if filt[4]:\n",
    "                    indices.append(filt)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_indices(filt, row):\n",
    "    \"\"\"Compare Indices\n",
    "    \n",
    "    Determines if an index falls into the filter range\n",
    "    \n",
    "    Args:\n",
    "        filt (list): filter information (in standard 1-D filter format)\n",
    "        row (astropy.Table): magnitude data on one star\n",
    "        \n",
    "    Returns:\n",
    "        (boolean): Whether or not the star passes all the filter conditions\n",
    "    \"\"\"\n",
    "    #allow me to detail the 1-D filter format\n",
    "    \n",
    "    #filter = [lower bound, upper bound, magnitude A, magnitude B, Boolean if the filter is valid]\n",
    "    #filter = [lbound, ubound, a, b, True/False]\n",
    "  \n",
    "    \n",
    "    a = filt[2]\n",
    "    b = filt[3]\n",
    "    \n",
    "    if a not in row.colnames or b not in row.colnames:\n",
    "        return False\n",
    "    else:\n",
    "        x = float(row[a]) - float(row[b])\n",
    "\n",
    "        if filt[0] <= x and filt[1] >= x:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def index_filterator(data, deviations = 1, threshold = 2/3):\n",
    "    \"\"\"Index Filterator\n",
    "    \n",
    "    Stores coordinates of stars that pass filter conditions in table, can be written to file\n",
    "    \n",
    "    Args:\n",
    "        data (astropy.Table): Astropy data\n",
    "        deviations (float?): number of standard deviations from mean to calc range (int or float preferred?)\n",
    "        threshold (float): fraction of stars contained within cluster region for cluster to be considered valid\n",
    "        \n",
    "    Returns:\n",
    "        (astropy.Table): Coordinates of LARP candidates\n",
    "    \"\"\"\n",
    "    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    #if you want modular stdevs, here's the place to do so\n",
    "    #go thru the following function to find it!!!!!!!!!!!!\n",
    "    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    indices = filter_generator(larp_table, deviations,threshold)\n",
    "    names_cheat = larp_table.colnames\n",
    "       \n",
    "    possible_larps = Table(names=names_cheat)\n",
    "    \n",
    "    for row in data:\n",
    "        passes_test = []\n",
    "        for index in indices:\n",
    "            passes_test.append(compare_indices(index, row))\n",
    "            \n",
    "        if False not in passes_test:\n",
    "            possible_larps.add_row(row)\n",
    "    \n",
    "    n_larp_cands = len(possible_larps['ra'])\n",
    "    print('\\nThere are',str(len(indices)),'usable filters!')\n",
    "    print('There are',str(n_larp_cands),'potential LARPs in this dataset!')\n",
    "    \n",
    "    return possible_larps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in data tables\n",
    "larps_sdss = ascii.read('LARP Characteristics-SDSS.csv')\n",
    "larps_wise = ascii.read('LARP Characteristics-WISE.csv')\n",
    "larps_xmm  = ascii.read('LARP Characteristics-XMM.csv')\n",
    "\n",
    "sdss_table = ascii.read('Skyserver_SQL6_25_2018 7_25_30 PM.csv')\n",
    "wise_table = ascii.read('wise_results.tbl')\n",
    "xmm_full = ascii.read('BrowseTargets.8264.1539051979', delimiter='|', header_start=2, data_start=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Organize LARPs\n",
    "larp_data = [larps_sdss, larps_wise,larps_xmm]\n",
    "larp_table = super_tableizer(larp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Organize Survey Data\n",
    "survey_data = [sdss_table, wise_table]\n",
    "survey_table = super_tableizer(survey_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prelim_larps = index_filterator(survey_table,2,7/9)\n",
    "#if the threshold (3rd argument) is >=7/9 then it breaks, saying \"ValueError: Mismatch between number of vals and columns\"\n",
    "#Figure out what this means and FIX IT PLEASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prelim. Results/Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "stdev = 1: 5 Filters, 67 Candidates\n",
    "stdev = 2: 27 Filters, 0 Candidates\n",
    "\n",
    "I like hte second one's results, but the 27/36 possible filters being successful gives me heartburn\n",
    "That's ~kinda~ sus to me, especially given all the \"7 stars in range\" I'm seeing :thinking:\n",
    "Would it be worth it to change the amount of LARPs that make a valid filter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Mk2, it seems that the lack of masking caused the number of filters to rocket up, but to also shrink the number of potential LARPs... Interesting, but also concerning.\n",
    "\n",
    "However, with stdev=2, the filters increase, like expected... but to include all possible filters! Worse yet, the number of candidates **INCREASED** I am confident that the issue lies in the values I masked\n",
    "\n",
    "I believe the issue lied in how the values were recorded in the data. I manually changed the masked values to blank spots. I cannot remember if these were originally zero or blank... I hope it was the latter!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
